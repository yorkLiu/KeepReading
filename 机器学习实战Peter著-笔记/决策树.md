# 决策树
> 决策树是一种用于对实例进行分类的树形结构。决策树由节点（node）和有向边（directed edge）组成。节点的类型有两种：内部节点和叶子节点。其中，内部节点表示一个特征或属性的测试条件（用于分开具有不同特性的记录），叶子节点表示一个分类。

> 一旦我们构造了一个决策树模型，以它为基础来进行分类将是非常容易的。具体做法是，从根节点开始，地实例的某一特征进行测试，根据测试结构将实例分配到其子节点（也就是选择适当的分支）；沿着该分支可能达到叶子节点或者到达另一个内部节点时，那么就使用新的测试条件递归执行下去，直到抵达一个叶子节点。当到达叶子节点时，我们便得到了最终的分类结果。

* 优点: 计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据
* 缺点: 可以产生过度匹配问题
* 适用数据类型: 数值型和标称型

## 名词解析
* 基尼不纯度 (Gini Impurity): 是一种度量集合无序程度的方法。简单来说是从一个数据集中随机选取子项，度量其被错误分类到其他分组里的概率。
* 信息熵 (Entropy): 熵的概念主要是指信息的混乱程度，变量的不确定性越大，熵的值也就越大。
* 信息增益(Information gain): 信息增益指的是划分熵的变化。
